{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45179cef-04bb-4cf5-8a45-8ef1ff37011d",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f430d06c-7fd3-4775-9064-2cd4e3f59f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries used in this project:\n",
      "- Python 3.10.13 (main, Sep 11 2023, 08:21:04) [Clang 14.0.6 ]\n",
      "- NumPy 1.26.4\n",
      "- Matplotlib 3.9.2\n",
      "- scikit-learn 1.5.1\n",
      "- TensorFlow 2.10.0\n",
      "- Keras 2.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys  # Read system parameters.\n",
    "\n",
    "import keras  # Provide a frontend for TensorFlow.\n",
    "import matplotlib as mpl  # Create 2D charts.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # Work with multi-dimensional arrays and matrices.\n",
    "import sklearn  # Perform data mining and analysis.\n",
    "import tensorflow  # Train neural networks for deep learning.\n",
    "from keras import datasets\n",
    "from numpy.random import seed\n",
    "\n",
    "\"\"\"Summarize the software libraries used.\"\"\"\n",
    "print(\"Libraries used in this project:\")\n",
    "print(\"- Python {}\".format(sys.version))\n",
    "print(\"- NumPy {}\".format(np.__version__))\n",
    "print(\"- Matplotlib {}\".format(mpl.__version__))\n",
    "print(\"- scikit-learn {}\".format(sklearn.__version__))\n",
    "print(\"- TensorFlow {}\".format(tensorflow.__version__))\n",
    "print(\"- Keras {}\\n\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e048fb-6fb6-4915-95dd-73d17c267d5c",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c923669-5a48-4d47-82b7-ca191bbb99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25000 training records.\n",
      "Loaded 25000 test records.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=10000)\n",
    "print(\"Loaded {} training records.\".format(len(X_train.data)))\n",
    "print(\"Loaded {} test records.\".format(len(X_test.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037e374-d686-47c6-887f-89e03e3391a2",
   "metadata": {},
   "source": [
    "**Spotlights**\n",
    "\n",
    "- This is the complete IMDb movie review dataset consisting of 25000 review records.\n",
    "- This is a Keras version that has been preprocessed, using a different method than previously applied.\n",
    "- Instead of loading the entire dataset, the num_words parameter restricts it to the 10,000 most frequently used words, with any words outside this range represented by a special character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e533a-3a2a-4512-a744-42aef5b6cf92",
   "metadata": {},
   "source": [
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d59073-daec-4cf7-9106-12bfe67f6ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for the last example :\n",
      "\n",
      "[1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9]\n",
      "\n",
      "\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Examine the last example's features.\"\"\"\n",
    "\n",
    "print(\"Features for the last example :\\n\")\n",
    "print(X_train[-1])\n",
    "print(\"\\n\")\n",
    "print(\"Label: {}\".format(y_train[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fa5b7-9270-45e2-afa5-c67e929fa697",
   "metadata": {},
   "source": [
    "**Spotlights** \n",
    "\n",
    "- This output highlights the characteristics derived from the last movie review.\n",
    "- Each characteristic corresponds to a word in the review, listed in order of appearance.\n",
    "- The numerical value assigned to each characteristic indicates the word's frequency rank within the dataset, with common words receiving lower numbers and rare words getting higher ones. The label for this example is 0, indicating a negative sentiment in a binary classification scenario, where 1 would denote a positive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95467184-53a6-41c4-82b0-9922733c0445",
   "metadata": {},
   "source": [
    "### Interpret the encoded data accurately to transform sequence values into meaningful text.\n",
    "\n",
    "- The first and second lines will convert each numerical feature into its corresponding word by using a predefined dictionary for the dataset.\n",
    "- In line six, any unfamiliar word will be substituted with a question mark (?).\n",
    "- This process ensures that all numerical values are accurately represented in a more understandable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "976df64f-d463-432c-95b1-85c5b06c3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = datasets.imdb.get_word_index()\n",
    "index_dictionary = dict([(value, key) for (key, value) in index.items()])\n",
    "\n",
    "\"\"\"To enhance clarity, substitute any unfamiliar terms with '?'.\"\"\"\n",
    "decoded = \" \".join([index_dictionary.get(i - 3, \"?\") for i in X_train[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b61cc-0a42-404e-bff1-ee982efea771",
   "metadata": {},
   "source": [
    "### Analyze the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fbdcb94-a13f-468d-97cd-bdf7048515af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ? as a big fan of the original film it's hard to watch this show the ? set ? and ? ? sets rob any style from this remake the mood is never there instead it has the look and feel of so many television movies of the seventies crenna is not a bad choice as walter ? but his snappy wardrobe and ? apartment don't fit the mood of the original or make him an interesting character he does his best to make it work but samantha ? is a really bad choice the english accent and california looks can't hold a candle to barbara ? ? voice and sex appeal lee j ? tries ? to fashion barton ? but even his performance is just gruff without style br br it feels like the tv movie it was and again reminds me of what a remarkable film the original still is\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e2b3c-0d3a-4f16-9b27-6aebdac7ce07",
   "metadata": {},
   "source": [
    "**Spotlights** \n",
    "\n",
    "Upon reading the text, it is evident why it received a negative label.\n",
    "\n",
    "- By examining the words alongside their numerical rankings, it becomes clear that the order is logical. For instance, the word \"this\" ranks 14, showing it is quite frequent, while \"rob\" ranks 2098, suggesting it is much rarer.\n",
    "- The review's text is presented in a simplified manner, lacking punctuation and capital letters, which makes it easier for the neural network to analyze.\n",
    "- Further text processing could involve eliminating stop words or extracting lemmas, but this level of analysis is adequate for the moment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
