{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45179cef-04bb-4cf5-8a45-8ef1ff37011d",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f430d06c-7fd3-4775-9064-2cd4e3f59f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries used in this project:\n",
      "- Python 3.10.13 (main, Sep 11 2023, 08:21:04) [Clang 14.0.6 ]\n",
      "- NumPy 1.26.4\n",
      "- Matplotlib 3.9.2\n",
      "- scikit-learn 1.5.1\n",
      "- TensorFlow 2.10.0\n",
      "- Keras 2.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys  # Read system parameters.\n",
    "\n",
    "import keras  # Provide a frontend for TensorFlow.\n",
    "import matplotlib as mpl  # Create 2D charts.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # Work with multi-dimensional arrays and matrices.\n",
    "import sklearn  # Perform data mining and analysis.\n",
    "import tensorflow  # Train neural networks for deep learning.\n",
    "from keras import datasets\n",
    "from numpy.random import seed\n",
    "\n",
    "\"\"\"Summarize the software libraries used.\"\"\"\n",
    "print(\"Libraries used in this project:\")\n",
    "print(\"- Python {}\".format(sys.version))\n",
    "print(\"- NumPy {}\".format(np.__version__))\n",
    "print(\"- Matplotlib {}\".format(mpl.__version__))\n",
    "print(\"- scikit-learn {}\".format(sklearn.__version__))\n",
    "print(\"- TensorFlow {}\".format(tensorflow.__version__))\n",
    "print(\"- Keras {}\\n\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e048fb-6fb6-4915-95dd-73d17c267d5c",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c923669-5a48-4d47-82b7-ca191bbb99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25000 training records.\n",
      "Loaded 25000 test records.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=10000)\n",
    "print(\"Loaded {} training records.\".format(len(X_train.data)))\n",
    "print(\"Loaded {} test records.\".format(len(X_test.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037e374-d686-47c6-887f-89e03e3391a2",
   "metadata": {},
   "source": [
    "**Spotlights**\n",
    "\n",
    "- This is the complete IMDb movie review dataset consisting of 25000 review records.\n",
    "- This is a Keras version that has been preprocessed, using a different method than previously applied.\n",
    "- Instead of loading the entire dataset, the num_words parameter restricts it to the 10,000 most frequently used words, with any words outside this range represented by a special character."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
